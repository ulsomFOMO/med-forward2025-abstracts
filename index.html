<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>FOMO Conference 2025 - Poster Abstracts</title>
  <link rel="stylesheet" href="styles.css">
</head>
<body>
  <header>
    <div class="container">
      <h1>2025 MED-FORWARD CONFERENCE</h1>
      <p>BIG IDEAS FOR THE FUTURE OF HEALTH CARE</p>
    </div>
  </header>

  <div class="container">
    <section id="abstracts">
      <h2>Abstracts</h2>

      <!-- Abstract 1 -->
      <div class="abstract">
          <p><strong>Poster Presentation</strong></p>
        <h3>ShuntSense: A Non-Invasive, Real-Time Monitoring System for VP Shunt Function</h3>
        <p class="authors"><strong>Authors:</strong> Mustafa Almosawi, BS, Emilia Wang, BA, Tristan Svoboda, BA, Aaron Buckley, BS, Alyssa W Kabithe, BS, Jacob Frank, Ethan Elkins, Rawan Ahmed, Guruprasad Giridharan, PhD, Brian Williams, MD, Joseph Neimat, MD, MBA.</p>
        <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Louisville</p>
        <p class="content">
            <strong>Abstract:</strong> Hydrocephalus is a life-threatening neurological disorder affecting over one million people worldwide. The primary treatment, ventriculoperitoneal (VP) shunts, have alarmingly high failure rates—30% 
            within 2 years and 98% within 10 years. Current diagnostic methods, such as CT and MRI scans, are costly, expose patients to radiation, and often fail to definitively confirm shunt functionality. Shunt failures can lead to 
            severe neurological deterioration, emergency surgeries, and increased mortality. A reliable, noninvasive, real time monitoring solution is critical to improving patient outcomes. ShuntSense is an innovative, 
            cost-effective device that provides real time, noninvasive monitoring of cerebrospinal fluid (CSF) flow in VP shunts. It confirms flow status, eliminating the need for multiple imaging and invasive procedures. 
            Compared to current methods, ShuntSense has the potential to offer faster and more reliable diagnostics, reduced radiation exposure, and lower costs, making frequent monitoring more accessible. 
            By enabling early detection of shunt malfunctions, this technology has an advantage to potentially prevent neurological decline, reduce hospitalizations, and improve the quality of life for patients suffering from hydrocephalus. 
            The early prototype demonstrated the feasibility of the device. Currently, ShuntSense is in its early stages of development and further advancements are necessary to make it widely available. Specifically, 
            more funding needs to be obtained to conduct patient studies next to further test this device for more experimental results to analyze and refine its design for optimizing diagnostic accuracy.
        </p>
      </div>

      <!-- Abstract 2 -->
      <div class="abstract">
          <p><strong>Poster Presentation</strong></p>
        <h3>TurnTracker: A Novel Device to Monitor Patient Turning in the ICU: Enhancing Care and Reducing Pressure Ulcer Incidence</h3>
        <p class="authors"><strong>Authors:</strong> Katherine Cermack B.S. Biology, B.S. Neuroscience; Ansley Cooper B.S. Mechanical Engineering; Aashka Sheth B.A. Neuroscience; Maya Reddy B.S. Biology; Jacob Markert B.A. Biology, M.S. Physiology; Sarah Swartz B.S. Bioengineering; 
          Isabelle Lai MEng Bioengineering; Kandis Adkins M.D.; Alex Ng M.D.; Tommy Roussel M.S., Ph.D.</p>
        <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Louisville</p>
        <p class="content">
            <strong>Abstract:</strong> Background: Pressure ulcers are a common and costly complication in intensive care unit (ICU) patients, often resulting from prolonged periods without adequate repositioning. 
            Despite established turning protocols, adherence can be inconsistent. Our team has created an innovative device to address this issue, providing real-time monitoring of patient positioning and automated integration 
            with hospital electronic medical record (EMR) systems.

            Objective: This project evaluates the usefulness of TurnTracker in reducing pressure ulcer incidence by ensuring adherence to turning protocols.

            Methods: The device was designed to detect and differentiate patient positioning on the left or right side through non-invasive sensors. Data will be transmitted securely to the hospital EMR, 
            enabling real-time tracking of turning intervals. Incidence of pressure ulcers, hospital acquired cost of pressure ulcer management, and associated costs of manufacturing will be included.

            Results: ICUs using the device notice a reduction in pressure ulcer diagnoses due to increased adherence of staff to patient rotation schedules and accurate documentation of these turns. 
            Hospitals therefore experience a reduction in pressure ulcer related lawsuits. Implementation of the device leads to a $15.7 million reduction in hospital associated pressure ulcer costs compared to baseline.

            Conclusion: Our novel device, TurnTracker, addresses a critical need in ICU care by objectively monitoring patient turning, improving adherence to protocols, and 
            significantly reducing the incidence and associated costs of pressure ulcers. Future research will focus on scaling implementation across multiple hospitals and exploring additional features for broader clinical applications.

        </p>
      </div>

      <!-- Abstract 3 -->
      <div class="abstract">
        <p><strong>Oral Presentation</strong></p>
        <h3>The Applicability of Google Lens in Dermatology: A Retrospective Diagnostic Accuracy Study in Over 150 Patients</h3>
        <p class="authors"><strong>Authors:</strong> Mindy N. Baker, BS; Camryn Slone, BS; Chase L. Wilson, MD</p>
        <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Kentucky</p>
        <p class="content">
            <strong>Abstract:</strong> Google Lens (GL) recently expanded its artificial intelligence-based image comparison feature to identify skin conditions. Specifically, GL accesses public images across Google to provide a 
            list of up to 8 diagnoses that appear most similar to skin conditions captured in user-provided photos. GL remains understudied in literature, specifically regarding its accuracy in detecting skin cancer. 
            Using official diagnoses provided by visiting a dermatologist and histopathologic confirmation as our gold standard, we aimed to investigate Lens’s performance in real-world patients and associations to gender, 
            age, and Fitzpatrick phototype. We recruited all patients whose conditions were pathologically confirmed to be basal cell carcinoma, benign nevus, dysplastic nevus, melanoma, psoriasis, seborrheic keratosis, 
            or squamous cell carcinoma from January 1 to November 30, 2023, at a single-center dermatology clinic. 152 patients were enrolled, which led to 257 images of distinct skin conditions initially available for testing. 
            Lens was 54.0% correct within the first diagnosis, 85.4% correct within the first 3 diagnoses, and 95.1% correct within all diagnoses provided. Unsurprisingly, the sensitivity for all conditions increased and specificity 
            decreased as more Google diagnoses were considered along the top-1, top-3, and top-8 results. However, nearly every diagnosis had a sensitivity greater than 90% when all outputs were considered. 
            This study helps dermatologists provide anticipatory guidance regarding the patient usage of Lens. This can also open the way for increased patient education and quicker access to dermatologic care. 
            On the other hand, Lens can foster misinformation and undue stress if used without confirmation.
        </p>
      </div>

      <!-- Abstract 4 -->
      <div class="abstract">
          <p><strong>Poster Presentation</strong></p>
          <h3>Carpal Tunnel Syndrome: Do Large Language Models Utilize the Clinical Practice Guidelines?</h3>
          <p class="authors"><strong>Authors:</strong> Behrad Bakhtiari Sirjani, BS; Michaela Dukes, BS; Luke Robinson, MD; Ethan Blackburn, MD</p>
          <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Louisville School of Medicine</p>
          <p class="content">
              <strong>Abstract:</strong> Introduction: Carpal tunnel syndrome (CTS) is a common entrapment neuropathy, and as patients increasingly seek health information online, the role of artificial intelligence (AI) in
              providing accurate medical advice is gaining attention. This study evaluates the responses of two large language models (LLMs), ChatGPT and Google Gemini, regarding CTS management, comparing their outputs to
              established clinical practice guidelines (CPGs) in terms of accuracy, completeness, and readability.

              Methods: Seven questions related to CTS treatment were developed and posed to both ChatGPT and Google Gemini. The generated responses were assessed by eight fellowship-trained hand surgeons, who independently
              classified each answer as ""appropriate,"" ""appropriate but incomplete,"" or ""inappropriate."" Readability was evaluated using a standardized online calculator that assessed multiple readability formulas.

              Results: Out of 112 total responses evaluated, 76 were deemed appropriate, with ChatGPT providing 46 appropriate responses compared to 30 from Gemini. Readability analysis indicated that ChatGPT’s responses
              averaged at a 12th-grade reading level, while Gemini’s averaged a 10th-grade level. Notably, 24 responses were graded as ""appropriate but incomplete,"" emphasizing the need for comprehensive information.

              Conclusion: This study demonstrates the potential of AI-driven platforms in enhancing patient education on CTS management. ChatGPT outperformed Gemini in accuracy, but both models showed limitations in completeness.
              The findings highlight the importance of ensuring that AI-generated health information is not only accurate but also accessible to patient populations. Future research should focus on improving the integration of AI
              with healthcare provider insights to enhance patient outcomes and understanding.

          </p>
      </div>

      <!-- Abstract 5 -->
      <div class="abstract">
          <p><strong>Poster Presentation</strong></p>
          <h3>Virtual Reality in Neurology Residency: A Pilot Study to Strengthen Neuroanatomy Knowledge</h3>
          <p class="authors"><strong>Authors:</strong> Derek Bass; Ayush Gupta, MD; Sydney-Nev Wichmann, MS; Laura Weingartner, PhD; Daniela Terson de Paleville, PhD</p>
          <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Louisville School of Medicine</p>
          <p class="content">
              <strong>Abstract:</strong> "Neuroanatomy is vital in the clinical practice of neurology, as it guides localization and differential diagnoses, but the rigor of residency leaves little time to review fundamentals. 
              Efficient yet in-depth tools are needed to refresh and bolster foundational material for the role. Recently established as an effective medical educational resource, virtual reality (VR) is increasingly used 
              to learn anatomy and surgical procedures, but studies are needed to examine VR as a means to improve neuroanatomy knowledge of neurology residents.

              We hypothesized that VR could refine the educational experience of neurology trainees. Our objective was to create a VR-based curriculum on neuroanatomy of the brain for neurology residents, assess improvements in knowledge, 
              and evaluate perceptions and attitudes related to the learning experience.

              After an interactive orientation session, 5 neurology residents completed a 40-minute guided VR session of 50 brain features using Organon app on the Oculus 3 headset. This learning session was divided into 3 modules: 
              cerebrovascular arterial supply, cerebral venous sinuses, and ventricular anatomy and major cortical structures. Participants took a survey/quiz at 3 points: 1) Pre-VR to assess pre-conceived attitudes, 
              confidence in neuroanatomy, and preferred learning styles, plus 14 advanced brain anatomy questions that integrated prior knowledge; 2) Post-VR to assess perceptions around the experience and a 14-question 
              brain anatomy quiz; 3) 3 weeks later, participants completed a 14-question quiz with a new set of brain anatomy questions to asses long-term retention. Scores were compared with a one-way ANOVA.

              All participants found the technology easy to use, engaging, and an efficient use of time, but some commented that the level of detail could have been higher for advanced learners. 
              Although score difference between timepoints was insignificant (F=3.9, p=0.09), scores were highest after 3 weeks, suggesting possible knowledge retention and expansion over time. 
              The highest gains were in the arterial module.

              VR is an efficient and engaging way to strengthen neuroanatomy knowledge in neurology residents, and this pilot study should be adapted to a larger group of residents, for which current participants’ 
              comments are used to build a more robust and detailed VR exposure program. Evidence for long-term retention can be enriched by tracking changes in the neural anatomy categories of residents’ board and internal exam scores.


          </p>
      </div>

      <!-- Abstract 6 -->
      <div class="abstract">
          <p><strong>Poster Presentation</strong></p>
          <h3>Impact of Caregiver Support on Physical Activity in Individuals with Intellectual Disability: A Fitbit-Based Study</h3>
          <p class="authors"><strong>Authors:</strong> Lauryn Brasch MS, Mattison Hale, Philip May MD, Joseph Palmieri, Frank May</p>
          <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Louisville</p>
          <p class="content">
              <strong>Abstract:</strong> "The American Psychiatric Association defines intellectual disability (ID) as a neurodevelopmental condition affecting cognitive and adaptive functioning. 
              The ID community faces significant health disparities, including lower life expectancy, limited access to preventive care, and a higher prevalence of health complications. Sedentary behavior worsens these issues, 
              with obesity rates in adults with ID ranging from 28% to 71%, and research showing individuals with ID are sedentary for over 70% of the day. Reducing sedentary behavior is crucial to mitigating preventable health risks. 
              Caregiver support has been shown to enhance motivation for physical activity. This study examines physical activity and exercise goal completion in individuals with ID with caregivers versus self-caregivers.

              Six participants with ID were recruited from the Southwest Center in Louisville, KY, along with the caregivers of three participants. Each participant received a Fitbit device and customized exercise plan 
              that was demonstrated for clarity. Physical activity data was collected using Fitabase, which tracked Fitbit device data. Weekly reports detailed seven fitness parameters: total daily steps, light intensity minutes, 
              mild intensity minutes, moderate intensity, sedentary minutes, and resting heart rate. T-tests of unequal variance were conducted to find statistical significance.

              Individuals with ID who had a caregiver showed statistically significant differences in total daily steps(p=0.000), sedentary minutes (p=0.000), light intensity minutes (p=0.007), and mild intensity minutes  (p=0.042) 
              compared to self-caregivers. However, the two groups had no significant difference in moderate and high-intensity minutes. Additionally, there were statistically significant differences between individuals with ID and 
              their caregivers in total daily steps (p=0.000), light intensity minutes (p=0.000), sedentary minutes (p=0.000), and high intensity (p=0.0014).

              The data derived from Fitbit devices show that caregiver involvement is crucial in affecting how individuals with ID engage in physical activity. Through enhancing motivation, participation, and long-term adherence to 
              physical activity, caregiver involvement can help improve health outcomes for individuals with ID. Devices such as Fitbit can be useful in helping individuals with ID and their caregivers achieve health goals, 
              by providing data-driven insights"


          </p>
      </div>

      <!-- Abstract 7 -->
      <div class="abstract">
          <p><strong>Poster Presentation</strong></p>
          <h3>Responsible AI in Health Professions Training: Modeling AI and Human Collaboration in the Oversight of an AI-Powered Learning Platform</h3>
          <p class="authors"><strong>Authors:</strong> Alexa DeRegnaucourt, MS; Kate Jennings, BA; Andrew Zahn, MS; Neal Taliwal, BS; Michael Eack, BS; Seth Overla, MS; Laurah Turner, PhD</p>
          <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Cincinnati College of Medicine</p>
          <p class="content">
              <strong>Abstract:</strong> Purpose: Ensuring the ethical implementation of artificial intelligence (AI) tools poses a challenge as models become more capable and powerful, a phenomenon referred to as “the alignment paradox”. 
              Continuous monitoring of AI tools is one guideline for the responsible implementation of AI. Scalable oversight, where humans and AI collaborate in monitoring activities, is a method of continuous monitoring that can also 
              reduce resource burdens while maintaining interpretive rigor. Our study offers a framework for how AI and humans can partner to conduct thematic analysis of qualitative data, thus guarding against the alignment paradox.

              Methods: Second-year medical students at the University of Cincinnati College of Medicine completed eight clinical scenarios within 2-Sigma, an AI-driven educational platform. Four voluntary, in-person focus groups were 
              conducted to explore student evaluation of 2-Sigma as a learning tool. Focus group transcripts were analyzed using manual inductive thematic analysis by three independent human raters alongside an AI-driven (GPT-4o) 
              qualitative analysis following Braun and Clarke’s six-step framework. We then compared human- and AI-generated themes.

              Results: AI-generated analysis effectively supplemented human analysis. The AI generated a codebook and themes through inductive thematic analysis in a contextually relevant manner. Comparisons between human and 
              AI-generated themes demonstrated general congruence between their respective codes. While AI and human coding were largely congruent, AI struggled to synthesize complex themes that required deeper contextual understanding.

              Discussion: Initial results showed success in using AI for contextually relevant thematic analysis. The similarity in human- and AI-generated codes indicates a strong inter-rater agreement. The success of this 
              AI-generated thematic analysis lends itself as a potential tool to efficiently work alongside human analysis. Future directions include exploring the optimal working relationship between human and AI analysis 
              and exploring the application of multiple AI agents to simulate human rater deliberation during thematic analysis.

              Significance: Our findings suggest that human qualitative analysis, complemented with AI-generated initial codes, can reduce manual workload while preserving interpretive depth. Our approach has the potential 
              to inform future techniques for scalable oversight, which will augment the ethical adoption of AI in health professions education.


          </p>
      </div>

      <!-- Abstract 8 -->
      <div class="abstract">
          <p><strong>Poster Presentation</strong></p>
          <h3>Preventing 12-Lead Electrocardiogram Misplacement: A Novel Prototype</h3>
          <p class="authors">
              <strong>Authors:</strong> Ilaria Ferrari; Gabrielle Ogle; Nada Kaissieh; Priyadarshini Chandrashekhar; Juliana Cobb, MS; Riley Keene; Hector H. Dreyer; Brooke Dardano;
              Beth Spurlin, MD, PhD, MBA; In Kim, MD, MBA; Guruprasad Giridharan, PhD; Deborah Kozik, DO; Soham Dasgupta, MD
          </p>
          <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Louisville School of Medicine, National Science Foundation I-Corps Grant</p>
          <p class="content">
              <strong>Abstract:</strong> "Electrocardiograms (ECGs) are essential for diagnosing a wide range of cardiac conditions and are performed over 100 million times annually in the United States.
              However, an estimated 3.4 million ECGs are impacted by lead placement errors each year, which can falsely suggest abnormalities or mask serious pathology. If not promptly detected and corrected,
              these errors may lead to unnecessary interventions, delayed diagnoses, and increased healthcare costs, ultimately compromising patient safety. Repeating incorrectly performed ECGs can strain hospital resources
              and create an even greater burden in rural and resource-limited settings, where access to follow-up testing may be limited. Despite the widespread use of ECGs, current methods fail to reliably prevent lead misplacement,
              highlighting the urgent need for an easily implementable solution that reduces such errors, improves patient safety, and optimizes healthcare resource utilization. Current approaches to mitigate lead misplacement,
              such as retrospective manual and algorithmic detection, are time-consuming and remain prone to error.

              To address this challenge, we are developing a streamlined ECG lead placement system designed to revolutionize the current ECG procedure. This prototype consists of a plastic housing with pre-installed cables that
              are optimally arranged in a pre-defined layout for the correct anatomical placement of a standard 12-lead ECG. Our prototype is designed to work on all different body types and sizes, including pediatric and adult populations.
              By designing a more streamlined ECG cable interface, we aim to eliminate the need to manually check each lead position, reduce set up time, and address the widespread challenge of cable tangling.
              These device features are especially advantageous in high-acuity settings including emergency, ambulatory, and in-patient wards where both diagnostic accuracy and speed are critical in ensuring improved patient outcomes.
              By addressing one of the most persistent challenges in ECG placement, our prototype represents a significant advancement in cardiovascular diagnostics that aims to improve patient safety and reduce healthcare costs.

          </p>
      </div>

      <!-- Abstract 9 -->
      <div class="abstract">
          <p><strong>Poster Presentation</strong></p>
          <h3>Comparative Analysis of the Performance of ChatGPT, OpenEvidence AI, Deep Seek, and other Generative AI Models on Orthopaedic Exam Questions and Citation Review</h3>
          <p class="authors"><strong>Authors:</strong> Daniel Hayes, BS; Alyssa Barre, MD; Ryan Muchow, MD</p>
          <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Kentucky</p>
          <p class="content">
              <strong>Abstract:</strong> "Artificial intelligence (AI) has demonstrated increasing utility in medical education, particularly in assisting students with test preparation and knowledge reinforcement. 
              OpenAI’s ChatGPT-4.0, o3-mini, Open Evidence AI (OE), and Deep Seek are advanced AI models with applications in medical education. ChatGPT-4.0 and OE have both performed well on standardized medical exams, 
              including passing the United States Medical Licensing Examination (USMLE). While ChatGPT has previously shown strong performance on the Orthopaedic In-Training Examination (OITE), no studies have evaluated OE, 
              Deep Seek, or o3-mini performance on this exam. Additionally, little is understood about the quality of citation and evidence-based support for answer choices. Given their differences in training, 
              with OE utilizing curated medical literature database, while OpenAI and Deep Seek models rely on large, diverse datasets, this study aims to compare differences in accuracy, as well as the quality and 
              reliability of their citations.

              This study employs a cross-sectional comparative analysis in which AI models answer a set of non-image-based multiple-choice 2024 OITE questions sourced from AAOS ResStudy. Responses are evaluated based on accuracy, 
              thinking time, and citation quality. The citation analysis assesses factors such as verifiability of the source, journal indexing, level of evidence, and type of study.

              The study’s findings will provide insights into the relative effectiveness of these AI tools in medical education and their potential role in orthopaedic training. Understanding differences in AI model training, 
              citation sourcing, and answer generation can help optimize AI integration into medical learning and clinical decision-making using modern evidence-based reasoning. This research contributes to evaluating AI’s 
              evolving role in medicine.


          </p>
      </div>

      <!-- Abstract 10 -->
      <div class="abstract">
          <p><strong>Poster Presentation</strong></p>
          <h3>A Systematic Review of All-Arthroscopic Techniques for Triangular Fibrocartilage Complex Repair: Outcomes and Insights</h3>
          <p class="authors"><strong>Authors:</strong> Emma Heironimus, BS; Lawrence Lin, M.D.; Jadie De Tolla, M.D.</p>
          <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Louisville School of Medicine, NYU Langone Health</p>
          <p class="content">
              <strong>Abstract:</strong> Triangular fibrocartilage complex (TFCC) injuries are a common cause of ulnar-sided wrist pain and instability, often requiring surgical intervention.
              This systematic review evaluates the outcomes of all-arthroscopic TFCC repair in adult patients, focusing on pain relief, functional recovery, and complications. A total of 13 studies were included,
              reporting significant improvements in grip strength, pain (VAS scores), and standardized functional outcomes (MMWS, DASH). While the procedure showed promising results,
              variability in surgical techniques and rehabilitation protocols limited the ability to draw definitive conclusions. Complications, particularly ulnar nerve irritation,
              were observed but comparable to open techniques. Despite limitations in evidence quality, this review supports all-arthroscopic repair as an effective alternative to open surgery,
              with faster recovery and reduced invasiveness. Further research with standardized protocols and long-term follow-ups is needed to optimize patient outcomes and address existing knowledge gaps.
          </p>
      </div>

      <!-- Abstract 11 -->
      <div class="abstract">
          <p><strong>Poster Presentation</strong></p>
          <h3>STEAM Outreach through Data Sonification</h3>
          <p class="authors"><strong>Authors:</strong> Kayla Horne, Emily Guerrero, Lizzie Rice, Andrea Hernandez, Lordina Mensah, Jada Covington, Alexis Smith, Timothy Moyers, PhD; Michael Baker, PhD; Luke Bradley, PhD</p>
          <p class="affiliation">
              <strong>Affiliation/Grants:</strong> University of Kentucky; University of Kentucky College of Medicine Office of Community Advancement Stairway Funds and a Science Education Partnership Award (SEPA),
              Grant Number R25 GM132961, from the National Institute of General Medical Sciences (NIGMS) National Institutes of Health (NIH)
          </p>
          <p class="content">
              <strong>Abstract:</strong> In the wake of continuously evolving technology, demand for individuals pursuing STEM careers continues to increase. Interest in STEM careers commonly develops in middle school and beyond. 
              Further, it is vital that students be exposed to various resources and programs to foster their STEM-related interests.  Fostering student interest requires students to have a basic understanding of scientific concepts. 
              Given the increased complexity of these concepts, clearly communicating them to students is a challenge. To address this, we propose using data sonification, the method of converting information into sound, 
              to provide an interactive modality of exploring the molecular basis of disease. Our collaborative project with the University of Kentucky School of Music involved engineering specialized software, the Data Sonification 
              Synthesizer, as an interactive tool that illustrates important molecular concepts through sound. Designed for introductory middle school and high school students, each amino acid is converted to a musical note or tempo, 
              based on its hydrophobicity, to identify changes and disruptions in protein sequence and its function in the context of a cell. Using data sonification to demonstrate the molecular basis of widely known diseases, 
              such as osteogenesis imperfecta, epidermolysis bullosa simplex, Charcot-Marie-Tooth disease, sickle cell anemia, and more, our results show integrating the arts into STEM (forming STEAM) encourages students to 
              continue pursuing STEM careers in higher education. Following additional development and analysis of our software, dissemination of this tool to the Commonwealth of Kentucky will enhance STEM interest across the state.
          </p>
      </div>

      <!-- Abstract 12 -->
      <div class="abstract">
          <p><strong>Poster Presentation</strong></p>
          <h3>Outcome Comparison of Surgical ECMO Arterial Closure Surgical versus de novo Percutaneous Devices</h3>
          <p class="authors"><strong>Authors:</strong> Chris Jackel, BS; Masashi Kawabori, MD; Jamel Ortoleva, MD</p>
          <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Kentucky</p>
          <p class="content">
              <strong>Abstract:</strong> Background: Extracorporeal Membrane Oxygenation (ECMO) is a life-saving intervention for patients with severe cardiac or respiratory failure. Following VA ECMO,
              decannulation and arterial closure are critical steps, traditionally performed using a surgical cutdown approach. However, new percutaneous closure devices, including the suture-based ProGlide,
              and the plug-based MANTA offer less invasive alternatives. Despite their growing use, there is limited comparative evidence regarding their outcomes versus surgical methods.

              Objective: This meta-analysis aims to compare the outcomes of surgical VA ECMO decannulation to percutaneous closures using ProGlide and MANTA, specifically focusing on bleeding, limb ischemia,
              infection rates, and ICU length of stay.

              Methods: A systematic literature search was conducted through PubMed, Embase, and Google Scholar, identifying studies comparing surgical and percutaneous closure techniques. Studies were screened
              based on predefined inclusion criteria, and data were extracted from observational studies and randomized clinical trials. A total of 8 studies with 872 participants were included in the final analysis.

              Results: Our analysis found that both percutaneous devices were linked to lower infection rates and reduced limb ischemia compared to traditional methods. Additionally, ProGlide was also associated
              with significantly shorter ICU stays and reduced bleeding complications compared to surgical closure.

              Conclusion: Percutaneous vascular closure devices, particularly ProGlide and MANTA, may offer significant advantages over surgical closure in VA ECMO decannulation, including reduced complications,
              shorter ICU stays, and fewer infections. These findings support the growing use of percutaneous techniques as viable alternatives to surgery, though further studies are needed to confirm long-term
              outcomes and refine patient selection.

          </p>
      </div>

      <!-- Abstract 13 -->
      <div class="abstract">
          <p><strong>Poster Presentation</strong></p>
          <h3>F-18-Fluorodeoxysorbitol (FDS): A PET Radiotracer for Detecting Bacterial Infection</h3>
          <p class="authors"><strong>Authors:</strong> Hannah Khan, BA; Chin Ng, PhD; Junling Li, PhD; Huaiyu Zheng, MD</p>
          <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Louisville School of Medicine, James Graham Brown Foundation</p>
          <p class="content">
              <strong>Abstract:</strong> Several radiotracers can be used in medical imaging to detect bacterial infection. 2-F-18-Fluorodeoxysorbitol (FDS) is a PET (positron emission tomography) radiotracer that can be used to
              detect bacterial infections. Sorbitol serves as a unique sugar source for bacteria. Since normal tissues do not take up sorbitol, FDS is an attractive PET radiotracer for detecting lung infection.

              For in vitro experiments, it was predicted that with increasing levels of FDS, % uptake of FDS should remain constant if the amount of bacteria stays the same. For in vivo experiments, it was predicted that FDS could
              detect bacterial infection in the mice, and through the treatment with antibiotics, the amount of bacterial infection detected in the mice should decrease.

              For in vitro experiments, the bacterial strain Klebsiella pneumoniae was injected with increasing concentrations of FDS. Bacteria were exposed to various concentrations of FDS and the total counts of bacteria were
              measured to indicate the level of FDS uptake. For in vivo experiments, mice were initially injected with Klebsiella pneumoniae. Body weight and temperature were recorded throughout the five-day course of the experiment.
              After 36 hours, they were treated with the antibiotic meropenem (400 mg), with subsequent doses administered every 12 hours for the next three days. Additionally, imaging analysis was done with CT and PET scans and the
              region of interest (ROI) was measured in % injected dose per gram of tissue (%ID/g) for the left and right lung.

              The in vitro experiments demonstrated that despite the increasing amount of FDS added to the bacterial strain, there was no change in the % uptake and it stayed on average at about 7%. The in vivo experiments generally
              demonstrated that after being injected with Klebsiella pneumoniae and with the course of antibiotic treatment, the amount of infection detected in the mice decreased over time. The values for the mice would typically
              start at around 1 %ID/g and decrease to about 0.3-0.4 %ID/g over the course of antibiotic treatment. This trend was not specific to all mice as each mouse responds to antibiotic treatment slightly differently.

              The data collected in this study provides useful information about detecting bacterial infection. The high specificity and ability of FDS makes it a promising tool for clinical use in diagnosing and monitoring
              bacterial infections.

          </p>
      </div>

      <!-- Abstract 14 -->
      <div class="abstract">
          <p><strong>Poster Presentation</strong></p>
          <h3>Ker-CT Cells: A New Model to Study iAs-induced Genomic Instability in Keratinocytes</h3>
          <p class="authors"><strong>Authors:</strong> Tala M. Maya, BS; Alexandra N. Nail, PhD; Sheila D. Thomas, MS; Sandra S. Wise, PhD; J. Christopher States, PhD</p>
          <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Louisville School of Medicine. This research was supported by NIH/NIEHS grants R01ES027778, T35ES014559, and P30ES030283, and American Cancer Society PF-23-1153675-01-DMC.</p>
          <p class="content">
              <strong>Abstract:</strong> "Background: Genomic instability, including chromosomal instability, is a hallmark of cancer. Inorganic arsenic (iAs) is a class 1 human carcinogen and chronic exposure causes cutaneous 
              squamous cell carcinoma (cSCC). iAs is a well-known clastogen that promotes chromosomal instability (e.g, deletions, inversions, duplications, and translocations in chromosomes). HaCaT cells are the classical model used to study molecular mechanisms responsible for iAs-induced skin carcinogenesis. However, HaCaT cells are pseudotetraploid, making them suboptimal for identifying chromosomal abnormalities that may drive iAs-induced cSCC by karyotyping analyses. Ker-CT cells are near diploid (45-49 chromosomes) and are therefore better suited for studies aimed at identifying chromosomal abnormalities. Determining which chromosomal abberations occur in Ker-CT cells chronically exposed to iAs will aid in the identification of molecular mechanisms responsible for iAs-induced skin cancer.

              Hypothesis: Chronic arsenic exposure promotes chromosomal instability in Ker-CT cells.

              Methods: Triplicate, independent, passage-matched cultures of immortalized human skin epithelial cells (Ker-CT) were exposed for 45 weeks to iAs (0 or 100 nm). Ker-CT cells were plated and 60 hours after plating, 
              colcemid was added. After 2 hours of colcemid exposure, cells were harvested and prepped for karyotyping analyses. Applied Spectral Imaging (ASI) System was used to karyotype the metaphases to assess chromosomal 
              instabilities present. PRISM 10 software was used to create final graphs of data and to perform statistical analyses. Statistical testing was completed using Welch’s two-tailed t-test. Statistical significance was 
              set at p ≤ 0.05.

              Results: Chromosomal instability was observed in Ker-CT cells exposed chronically to 100 nM iAs for 45 weeks. iAs-exposed cultures contained significantly more chromosomal abberations including deletions, inversions, 
              and translocations. A persistent translocation between the q arm of the X chromosome and q arm of chromosome 5 was observed in one of the iAs-exposed cultures. The average number of chromosomal abnormalities across 
              cultures is stochastic with chronic iAs exposure where one iAs culture did not have many structural chromosomal abberations compared to the other two iAs exposed cultures.

              Conclusions: Chronic iAs exposure causes structural chromosomal instability in Ker-CT cells. The deletions, inversions, and translocations observed may be due to increased use of non- homologous end joining repair (NHEJ) .

          </p>
      </div>

      <!-- Abstract 15 -->
      <div class="abstract">
          <p><strong>Poster Presentation</strong></p>
          <h3>Assessing the Effectiveness of AI-Enhanced Triage Systems in Reducing Wait Times for Outpatient CT Scans</h3>
          <p class="authors"><strong>Authors:</strong> Alexander Myers, MS; Royale Lim, DO; Nita Nair; Nicholas Kemper, MD; MJ Negahdar, MBA, Ph.D; Jonathan Joshi, MD; Sohail Contractor, MD</p>
          <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Louisville, School of Medicine</p>
          <p class="content">
              <strong>Abstract:</strong> Purpose: This study assesses the efficacy of implementing results from a computer-aided triage and prioritization AI system (CADt) into the radiologist worklist for patients undergoing outpatient (OP)
              CT scans.

              Materials and Methods: Data were gathered at a large academic health system over two ten-month periods, centered around the availability of AI results (Aidoc, Tel Aviv, Israel) in the radiologists' worklist (WL).
              The pre-WL period spanned from 05/2022 to 02/2023, while the post-WL period was from 04/2023 to 01/2024. During the study, AI notifications were always available and displayed to the radiologists in the standard Aidoc interface.
              The variable studied here is the impact of worklist integration/prioritization based on the AI alerted findings. The analysis focused on four CADt algorithms deployed in the OP setting: c-spine fractures (CFX), free air (FA),
              intracranial hemorrhage (ICH), pulmonary embolism (PE), incidental pulmonary embolism (iPE), and rib fractures (Rfx). A wait time metric was calculated for AI-notified cases with suspected positive findings and
              compared to negative, non-AI-notified cases. Wait time was defined as the duration between the completion of the study acquisition and the time a radiologist opened the case for report dictation.
              Median wait times were compared for both positive/negative cases and pre/post WL implementation.

              Results: A total of 146,607 OP CT exams were analyzed (14% CFX, 18% FA, 23% ICH, 4% PE, 13% Rfx, 26% iPE). The median wait time for OP patients was 95.7 minutes for positive cases and 409.3 minutes for negative cases
              in the post-WL period, compared to 145.8 minutes for positive cases and 216.1 minutes for negative cases in the pre-WL. Which resulted in a statistically significant observed prioritization impact of 44.1% (243.3 minutes,
              moods-test p < 0.05) post-WL implementation.
              Conclusion: The study demonstrated that integrating a computer-aided triage and prioritization AI system (CADt) into radiologist worklists significantly reduced wait times for outpatient CT scans. The overall reduction of 44.1% in median wait times highlights the potential of AI to enhance medical diagnostic efficiency.

          </p>
      </div>

      <!-- Abstract 16 -->
      <div class="abstract">
          <p><strong>Poster Presentation</strong></p>
          <h3>FlexiForceps: A Novel Instrument for Upper Airway Surgeries</h3>
          <p class="authors"><strong>Authors:</strong> Anh Phan, BS; Nair Ankita, BS; Draw Iyla, BA MBE; Kahloon Lilah, BS; Alrefai Rahaf, BS; Chandran Swapna, MD</p>
          <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Louisville School of Medicine, NSF Regional I-Corps Grant Recipient</p>
          <p class="content">
              <strong>Abstract:</strong> Problem: ENT (ear-nose-throat)  surgeons are using surgical instruments not optimal for human anatomy. Most instruments used in upper airway procedures are straight while the
              human airway is curved. Existing instruments do not provide adequate mobility and visualization within complex spaces like the airway. This can lead to longer surgery times, surgeon fatigue,
              and an increased risk of mucosal tissue injury.
              Purpose: This report is intended to demonstrate how multidisciplinary biomedical design teams housed within medical schools can develop innovative solutions to contemporary surgical problems.
              The University of Louisville Bluegrass Biodesign Otolaryngology team developed a novel design for surgical forceps to be used in upper airway procedures that improves surgeon mobility.
              Methods: A team of five medical students and three undergraduate engineering students collaborated with experts within the University of Louisville of School of Medicine and the
              University of Louisville J.B. Speed School of Engineering to redesign the typical micro-laryngeal forceps used in upper airway procedures such as biopsies, direct bronchoscopies/ laryngoscopies,
              and tissue ablations. The team was housed under “Bluegrass Biodesign,” the School of Medicine’s biomedical innovation program. After shadowing several dozen upper airway procedures and noticing that
              ENT surgeons struggled to perform procedures with conventional instruments, the team proposed that a forceps with a hinge design near the tip could help surgeons better visualize and navigate the airway space.
              The hinged instrument could offer surgeons up to 90 degrees of mobility within one plane.  Using an existing 2.5mm micro-laryngeal grasping cup forceps, the engineers converted the forceps into a 3D computerized blueprint.
              They used the solid modeling computer-aided design (CAD) software SolidWorks to design a hinge on the existing instrument. This new instrument was then 3D printed in metal with the intention of testing
              the device on intubation manikins to demonstrate proof of concept. While this first attempt at prototyping resulted in a tangible product, the hinge design ended up being too bulky compared to the small bite-size
              of the micro-laryngeal forceps. New methods such as using a more complex pulley system to enable more precise movement is being explored.

          </p>
      </div>

      <!-- Abstract 17 -->
      <div class="abstract">
          <p><strong>Poster Presentation</strong></p>
          <h3>Use of Deep Learning for Personalized Patient Care in Interventional Radiology: A Review</h3>
          <p class="authors"><strong>Authors:</strong> Ronak K. Patel, BS; Merve, Ozen, MD</p>
          <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Kentucky</p>
          <p class="content">
              <strong>Abstract:</strong> Artificial intelligence (AI), specifically deep learning (DL), and machine learning (ML) are revolutionizing interventional radiology by advancing personalized patient care. 
              These computational models enhance various stages of clinical workflows, including pre-, peri-, and post-procedural tasks. In the pre-procedural stage, AI optimizes patient selection, risk assessment, 
              and image analysis, enabling early detection and diagnosis of diseases. AI tools such as computer-aided detection (CAD) systems have shown promise in identifying abnormal findings and reducing false positives, 
              while advancements in radiomics and population imaging facilitate personalized treatment planning by integrating clinical, genetic, and socioeconomic data. AI improves treatment precision and safety during the 
              peri-procedural stage. Technologies like augmented reality (AR) provide real-time guidance during procedures, such as needle localization and vascular imaging, enhancing accuracy and reducing radiation exposure. 
              Integration with fluoroscopic systems and other modalities has streamlined workflows, benefitting patients and clinicians. Post-procedurally, AI enables better outcome predictions and treatment optimization. 
              For example, ML algorithms have been used to predict responses to transarterial chemoembolization (TACE) and thermal ablation in hepatocellular carcinoma (HCC) patients. Additionally, AI-driven radiomics models 
              leverage imaging data to provide insights into disease progression and survival rates, paving the way for precision medicine. AI also holds significant potential in education and training. Virtual assistants, 
              touchless interfaces, and simulation tools enable radiology trainees to hone their skills while maintaining sterile environments during procedures. Furthermore, emerging technologies like virtual biopsies and 
              voice recognition software enhance diagnostic workflows and procedural efficiency. This review highlights AI's transformative impact in addressing complex challenges in IR, streamlining workflows, 
              and enhancing patient care. By integrating AI into routine practice, current and future interventional radiologists can deliver more precise, efficient, and personalized treatment, ultimately improving outcomes across the field.
          </p>
      </div>

      <!-- Abstract 18 -->
      <div class="abstract">
          <p><strong>Oral Presentation</strong></p>
          <h3>Phenome-wide Association Study Demonstrates Sex-Based Differences in Sensory Organ Phenotypes in Sjogren’s Syndrome</h3>
          <p class="authors"><strong>Authors:</strong> Onajia Stubblefield, MS; Brieann H. Sobieski, BS; Shari R. Lipner, MD, PhD</p>
          <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Louisville School of Medicine; Weill Cornell Medical College; Weill Cornell Medicine, Department of Dermatology</p>
          <p class="content">
              <strong>Abstract:</strong> We sought to address the gaps in understanding how Sjogren’s Syndrome (SS) differs between sexes in terms of comorbidities, clinical presentation, and diagnostic timelines by leveraging phenome-wide association studies
              (PheWAS) and electronic health records.

              Analysis was performed using data from the All of Us database, with SS cases identified by three or more occurrence codes in the EHR. Controlling for age, race/ethnicity, number of dates in the EHR, and EHR length,
              we performed EHR-based PheWAS to compare male SS participants with female SS participants. Phecodes which passed Bonferroni significance were then analyzed using Mann-Whitney U tests to compare median time after SS
              diagnosis between males and females with SS.

              We identified 169 males and 1554 females SS cases. Males had a later age at first SS ICD-9 or ICD-10 code than females (mean ± sd, 60 ± 14 and 54 ± 13, respectively, p < .001). 9 sensory organ phenotypes passed
              Bonferroni significance (p < 1.0 x 10^-4), all of which were associated with male rather than female sex. These included disorders of retina (OR = 2.78), keratoconjunctivitis (OR = 2.05), keratitis (OR = 2.36),
              meibomian gland dysfunction of eyelid (OR = 2.90), keratoconjunctivitis sicca (OR = 2.05), puckering of macula (OR = 3.07), hemorrhage of the eye (OR = 4.76), disorders of the cornea (OR = 2.79),
              and non-degenerative maculopathy (OR = 3.18). Furthermore, years after SS diagnosis for these 9 phenotypes was shorter for males than females. Significant differences (p < .05) were found for keratoconjunctivitis
              (0.00, 0.20, male vs. female, respectively), keratitis (0.00, 0.54), meibomian gland dysfunction of eyelid (0.58, 2.02), keratoconjunctivitis sicca (0.00, 0.23), and eye hemorrhage (0.07, 2.79).
              In sum, males had a later age than females at their first recorded SS ICD-9 or ICD-10 code. Sensory organ phenotypes, likely sequelae of SS, were more strongly associated with male sex and appeared earlier
              following SS diagnosis compared to females. Given the female predominance of SS, these findings suggest that male patients may experience a distinct disease trajectory or face under recognition of SS symptoms,
              potentially leading to delayed diagnosis, suboptimal care, and severe complications. Further research is needed to elucidate sex-based differences in disease progression and improve the timely recognition and
              management of SS in males.

          </p>
      </div>

      <!-- Abstract 19 -->
      <div class="abstract">
          <p><strong>Poster Presentation</strong></p>
          <h3>FlexPatch Pacing Wires: The Atraumatic Solution Keeping Your Heart in Rhythm</h3>
          <p class="authors"><strong>Authors:</strong> Quentin Wise; Mohammad Abou El-Ezz; Sidimohamed Elmoustapha; Sidney Johnson; Madeline Cissell; Kayley Stowers; Alaa Mahmoud; Shahab Ghafghazi, MD</p>
          <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Louisville</p>
          <p class="content">
              <strong>Abstract:</strong> Temporary epicardial pacing wires (TEPWs) are routinely used following cardiac surgery to manage transient arrhythmias. However, conventional TEPWs rely on suture-based fixation, which can cause myocardial injury,
              inflammation, and fibrosis. Critically, removal of these wires can lead to pericardial bleeding and, in some cases, cardiac tamponade, a life-threatening complication. To address these challenges,
              we propose a novel TEPW that utilizes a hydrogel adhesive for atraumatic epicardial fixation, eliminating the need for sutures while maintaining stable pacing function. This novel TEPW design integrates a biocompatible,
              insulative hydrogel that adheres reversibly to the epicardium. The hydrogel provides secure attachment while allowing for atraumatic removal, minimizing the risk of tissue damage and bleeding.
              In addition to facilitating stable electrical contact, the hydrogel also serves as an insulating barrier that may reduce aberrant conduction and unintended electrical interactions with surrounding myocardial tissue.
              By localizing pacing energy and preventing electrical leakage, this design could enhance pacing efficiency and reduce the risk of pacing-induced arrhythmias. The hydrogel-based TEPW offers multiple advantages
              over traditional sutured wires. By eliminating direct myocardial penetration, it could significantly reduce the incidence of pericardial effusion and tamponade. Furthermore, the simplified application and removal
              process may shorten procedural time and decrease post-surgical complications. The insulating properties of the hydrogel could also improve pacing precision while reducing the risk of unintended conduction disturbances.
              This proof-of-concept design represents a promising advancement in temporary cardiac pacing. Future research will focus on optimizing hydrogel composition for adhesion strength, electrical conductivity, and biocompatibility.
              In vitro validation and preclinical testing will be essential to assess the feasibility, stability, and long-term performance of this approach. If successful, this technology could redefine the standard of care for
              temporary epicardial pacing, improving patient safety and surgical outcomes.
          </p>
      </div>

      <!-- Abstract 20 -->
      <div class="abstract">
          <p><strong>Oral Presentation</strong></p>
          <h3>Artificial Intelligence-Driven Worklist Reprioritization Improves Turnaround Time of AI-Detected Free Intraperitoneal Air in the Emergency Department</h3>
          <p class="authors"><strong>Authors:</strong> Manting Xu, BA; Royale Lim, DO; MJ Negahdar, PhD, MBA; Jonathan Joshi, MD</p>
          <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Louisville School of Medicine, Department of Radiology</p>
          <p class="content">
              <strong>Abstract:</strong> PURPOSE: Detection of intraperitoneal free air (IFA) in the Emergency Department (ED) can be a surgical emergency that must be promptly identified. Here, we evaluate the impact of a computer-aided triage and
              prioritizing AI system (CADt) on turnaround time for positive and negative IFA cases.

              MATERIALS AND METHODS: This retrospective study was performed using ED CT scans analyzed for IFA and prioritized if detected positive by an AI-driven CADt algorithm (Aidoc, Tel Aviv, Israel).
              AI-detected positive and negative IFA CT scans were collected during a 10-month pre-AI worklist reprioritization period (May 2022-Feb 2023) and a 10-month post-AI worklist reprioritization period (April 2023-Jan 2024).
              Turnaround time, defined as time the study acquisition was completed to the time a radiologist opened the case for report dictation, was determined for AI-detected positive and negative cases.
              Median turnaround times were compared between AI-detected positive/negative cases and pre/post-AI worklist periods.

              RESULTS: This study included a total of 20,763 ED CT scans. There were 95 flagged positive cases and 7556 negative cases in the pre-AI worklist period. The post-AI worklist period consisted of 156

              flagged positive cases and 12956 negative cases.  Median turnaround time in the pre-AI worklist period was 15.4 minutes (IQR 17.5) for AI-detected positive cases and 14.6 minutes (IQR 15.6) for AI-detected negative cases.
              Median turnaround time in the post-AI worklist period was 13.3 minutes (IQR 17.1) for AI-detected positive cases and 15.5 minutes (IQR 19.5) for AI-detected negative cases. This resulted in an impact of 14.3%
              (2.2 minutes turnaround time) in the post-AI worklist period between in AI-detected positive and negative cases.

              CONCLUSION: AI-driven worklist reprioritization is associated with 14.3% (2.2 minutes) decreased turnaround time in AI-detected positive IFA cases. By prioritizing potential positive IFA cases,
              our results suggest that AI-driven worklist reprioritization can be a viable tool to assess IFA more quickly in the ED. Thus, the data indicate that integrating AI-triggered notifications with worklist
              prioritization delivers a significant improvement in the ED radiology workflow efficiency, going beyond the benefits of AI notifications alone, and facilitates more timely reporting of acute findings.

          </p>
      </div>

      <!-- Abstract 21 -->
      <div class="abstract">
          <p><strong>Poster Presentation</strong></p>
          <h3>An Artificial Intelligence-Driven Platform for Practice Question Generation</h3>
          <p class="authors"><strong>Authors:</strong> Andrew Zahn, MS; Seth Overla, MS; Weibing Zheng, PhDc; Christine Y. Zhou, MD; D.J. Lowrie, Jr., PhD; Sally A. Santen, MD, PhD; Laurah Turner, PhD</p>
          <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Cincinnati College of Medicine</p>
          <p class="content">
              <strong>Abstract:</strong> Board exams like the USMLE and ABIM are critical in medical education, influencing career paths and clinical outcomes. High-quality practice questions are key to preparation but creating
              them is resource intensive. Students often rely on costly commercial question banks, exacerbating educational inequities. AI offers a scalable solution, but prior applications using large language models (LLMs) have
              faced issues with scalability and oversight. This project aimed to develop a scalable AI-driven system to generate NBME-style questions with accuracy, efficiency, and alignment with best educational practices.

              Approach
              Our AI-driven question bank employed an iterative design using retrieval-augmented generation (RAG), human-in-the-loop oversight, and JavaScript Object Notation (JSON) validation to optimize question generation.
              The system was piloted in a Blood Systems course at the University of Cincinnati College of Medicine. AI-generated questions underwent faculty review before integration into a mobile-accessible repository,
              where students engaged with the questions, receiving performance-based feedback and AI-powered tutoring.

              Outcomes/Findings
              Of 507 AI-generated questions, 84% met NBME item-writing standards. The primary rejection reason (13%) was factual inaccuracy. While student engagement varied, initial trends suggested improved performance on related
              exam questions among users. Qualitative feedback was positive, highlighting AI’s potential in medical education but emphasizing the need for broader topic coverage.

              Lessons Learned/Next Steps
              This proof-of-concept demonstrated AI’s ability to efficiently generate high-quality questions while reducing faculty workload. Future work includes a multi-agent AI validation system to enhance accuracy,
              expansion across medical education, and refinement of domain-specific content through RAG and fine-tuning to ensure seamless integration into curricula."

          </p>
      </div>

      <!-- Abstract 22 -->
      <div class="abstract">
          <p><strong>Poster Presentation</strong></p>
          <h3>Investigating AI-Based ASD Detection with sMRI and SRS: Impact of Different p-Values</h3>
          <p class="authors"><strong>Authors:</strong> Mostafa Abdelrahim; Mohamed Khudri; Mohamed T. Ali; Yaser A. Elnakib; Ahmed Shalaby; Ali Mahmoud; Sohail Contractor; Gregory N. Barnes; Ayman El-Baz</p>
          <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Louisville</p>
          <p class="content">
              <strong>Abstract:</strong> Early diagnosis of Autism Spectrum Disorder (ASD) is crucial, as it significantly affects social and communication skills. Our previous research focused on ASD diagnosis using structural 
              magnetic resonance imaging (sMRI). In this study, we extend this work by analyzing different markers associated with varying statistical significance p-values to identify those yielding the highest performance, 
              enabling an objective behavioral assessment system for determining ASD severity using sMRI data. Our system consists of multiple steps: i) preprocessing sMRI data, normalizing intensity, and extracting brain regions 
              using the Desikan-Killiany atlas, ii) extracting radiomics features, including morphology and volumetric markers, from each parcellated brain region, iii) constructing a brain matrix to assess anatomical correlations 
              within and between hemispheres, iv) applying Recursive Feature Elimination to identify significant brain regions and radiomics features linked to behavioral severity, v) classifying severity levels 
              (mild, moderate, or severe) using a Support Vector Machine (SVM) classifier, and vi) conducting statistical analysis across multiple experiments to determine associated markers at different p-values (0.05 to 0.01), 
              which are then used to retrain and refine the model. We evaluated our system on the Autism Brain Imaging Data Exchange II dataset, comprising 521 ASD and 593 typically developing (TD) individuals. 
              Using 5-fold cross-validation, our system achieved an average classification accuracy of ~90% for final classification and consistent performance across different p-value markers. 
              Additionally, it accurately identified brain regions associated with each severity level, providing an objective alternative to traditional assessments such as the Autism Diagnostic Observation Schedule and 
              Autism Diagnostic Interview-Revised, marking a significant advancement in ASD diagnosis.

          </p>
      </div>

      <!-- Abstract 23 -->
      <div class="abstract">
          <p><strong>Oral Presentation</strong></p>
          <h3>Novel AI System for Non-Invasive Acute Renal Rejection Diagnosis</h3>
          <p class="authors"><strong>Authors:</strong> Ibrahim Abdelhalim, MD; Mohamed Abou El-Ghar, Professor; Amy Dwyer, MD; Rosemary Ouseph, MD; Sohail Contractor, Professor; Ayman El-Baz, Professor</p>
          <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Louisville, Computer Science and Electrical Engineering</p>
          <p class="content">
              <strong>Abstract:</strong> Acute rejection of transplanted kidneys significantly threatens patient outcomes and graft survival after renal transplantation, the gold-standard treatment for end-stage renal disease.
              Early and accurate detection of rejection is crucial to preserve graft function and improve long-term prognosis. However, inconsistencies in Diffusion-Weighted MRI (DW-MRI) protocols across scanners with
              varying magnetic field strengths (e.g., 1.5Tesla vs. 3Tesla) pose challenges, leading to variability in Apparent Diffusion Coefficient (ADC) measurements and complicating reliable diagnosis.

              To address these issues, we developed a novel, non-invasive AI-driven diagnostic system for detecting acute renal rejection using DW-MRI. The methodology involves several key steps.
              First, renal structures are anatomically segmented and aligned across different scanners to harmonize cortical-medullary boundaries, ensuring consistent analysis. ADC metrics are then computed within segmented
              graft regions to quantify diffusion properties. A fast-marching level sets algorithm performs 3D iso-surface decomposition of ADC maps, stratifying tissue from cortex to medulla for detailed spatial characterization
              of diffusion patterns.

              Statistical distribution profiles, represented as cumulative distribution functions (CDFs), are generated for ADC values across iso-surfaces. Pairwise Spearman’s rank correlation analysis captures relationships
              between kidney regions. Finally, a Transformer-based architecture interprets correlation matrices to classify grafts as stable or acutely rejected, leveraging Transformers' robust feature extraction capabilities
              for high diagnostic accuracy.

              Validated on a clinical trial cohort of 94 transplant recipients (40 acute rejection cases, 54 stable grafts), the model demonstrated exceptional performance under rigorous leave-one-patient-out cross-validation,
              achieving 98.7% accuracy, 97% sensitivity, and 100% specificity. These results highlight the system’s ability to mitigate scanner variability, offering a standardized approach to non-invasive renal transplant monitoring.

              By integrating AI-driven analysis with imaging techniques, the system demonstrates superior generalizability and diagnostic precision, enabling early rejection detection and improving patient outcomes and graft longevity.
              The success of this method underscores the value of combining computational techniques with medical imaging to overcome longstanding clinical diagnostic challenges.

          </p>
      </div>

      <!-- Abstract 24 -->
      <div class="abstract">
          <p><strong>Poster Presentation</strong></p>
          <h3>A Custom-Built CNN-Based CAD System for Accurate Brain Death Detection Using Perfusion Scintigraphy Imaging</h3>
          <p class="authors"><strong>Authors:</strong> Ahmed Alksas, MSc; MJ Negahdar, PhD; Yi Zhang, DO; Al-Hassan Abdelhalimr, BSc; Hashim Mohamed Farg, MBBCh; Mohammed Ali Badawy, MBBCh; Mohamed Abou El-Ghar, MD; Mohamed Ghazal, PhD; Sohail G. Contractor, MD; Ayman Sabry El-Baz, SR, PhD</p>
          <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Louisville</p>
          <p class="content">
              <strong>Abstract:</strong> Accurate determination of brain death is a critical medical challenge, essential for guiding clinical decision-making and ensuring appropriate patient management. 
              This study presents a computer-aided diagnostic (CAD) system utilizing artificial intelligence (AI) to detect brain death from perfusion scintigraphy images with high accuracy and efficiency. 
              The system is built on a custom-designed convolutional neural network (CNN) tailored to extract spatial features from imaging data and identify perfusion patterns indicative of brain death.

              The CNN model was trained on a dataset of 93 subjects, including 44 with uptake and 49 with no uptake. Model optimization was performed using the Adam optimizer with binary cross-entropy loss as the objective function. 
              The network was trained for 500 epochs, using a 10% validation split to monitor performance. The architecture was specifically designed to balance model complexity and generalization, 
              with convolutional layers capturing local patterns and fully connected layers performing classification.

              The CAD system achieved an accuracy of 95%, with a precision of 96%, recall of 94%, and an F1-score of 95%, demonstrating its effectiveness in detecting brain death. 
              These results suggest that the proposed system can support clinicians by providing fast, consistent, and reliable assessments.

              By leveraging deep learning, this system streamlines the diagnostic process and reduces subjectivity in image interpretation, supporting faster and more accurate clinical decisions. 
              Future work will focus on expanding the dataset and comparing the system’s performance with other state-of-the-art CAD models, underscoring the potential of AI in advancing clinical diagnostics.

          </p>
      </div>

      <!-- Abstract 25 -->
      <div class="abstract">
          <p><strong>Poster Presentation</strong></p>
          <h3>From HE to TRI: A Transformer-Based GAN for Precise Virtual Stain Conversion</h3>
          <p class="authors"><strong>Authors:</strong> Hossam Magdy Balaha, MSc; Ali Mahmoud, PhD; Ahmed Aboudessouki, MSc; Mohamed Azam, MSc; Dibson Gondim, PhD; Ayman El-Baz, PhD</p>
          <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Louisville</p>
          <p class="content">
              <strong>Abstract:</strong> Histopathological analysis is vital for diagnosing and managing chronic liver diseases, particularly in assessing fibrosis; a hallmark of conditions like NASH, hepatitis, 
              and alcoholic liver disease. While hematoxylin and eosin (HE) staining is widely used for routine histopathology due to its ability to visualize cellular structures, it struggles to highlight collagen, 
              which is essential for fibrosis evaluation. Masson's Trichrome (TRI) staining provides excellent contrast for collagen but requires additional tissue sections, incurs higher costs, 
              and introduces challenges such as misalignment between HE and TRI slides. To address these limitations, we propose TbGAN, a transformer-based generative adversarial network (GAN) framework for virtual HE-to-TRI staining. 
              It utilizes the global context modeling capabilities of transformers and the high-quality image generation of GANs to accurately transform HE-stained images into TRI-like images. 
              The framework incorporates a robust preprocessing pipeline that includes tile extraction, rigid-body registration, and free-form deformation (FFD) to ensure precise alignment between HE and TRI images. 
              Additionally, a weighted fusion mechanism balances identity preservation and cycle consistency by combining outputs from multiple configurations, enhancing robustness and generalizability. 
              Our experiments demonstrate that TbGAN achieves superior performance compared to existing methods. The fused configuration attains high similarity metrics, including Mutual Information (MI: 0.9987), 
              Structural Similarity Index (SSIM: 0.7618), and Normalized Cross-Correlation (NCC: 0.9369), while minimizing dissimilarity metrics such as Mean Squared Error (MSE: 63.386). 
              Qualitative analysis further confirms the framework's ability to generate high-quality virtual TRI images that closely resemble ground truth, preserving fine details such as collagen fibers and cellular boundaries. 
              This approach significantly reduces the need for physical restaining, saving time and resources while improving diagnostic workflows. By enabling accurate fibrosis assessment without additional tissue sections, 
              TbGAN has the potential to enhance digital pathology applications, including tumor detection, biomarker localization, and fibrosis quantification. Future work will focus on optimizing fusion weighting schemes, 
              extending the framework to other stain translations (e.g., HE to immunohistochemistry), and validating it on larger, diverse datasets.
          </p>
      </div>

      <!-- Abstract 26 -->
      <div class="abstract">
          <p><strong>Poster Presentation</strong></p>
          <h3>Impact of AI Work List Integration on Reporting Time for Cervical Spine Fractures in the Emergency Department</h3>
          <p class="authors"><strong>Authors:</strong> Nicholas Kemper, MD; Nita Nair; Alexander Myers, MS; Royale Lim, MD; MJ Negahdar, PhD; Jonathan Joshi, MD</p>
          <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Louisville School of Medicine, Department of Radiology</p>
          <p class="content">
              <strong>Abstract:</strong> PURPOSE: This study aims to assess computer-aided triage and prioritization AI system integration into radiologists’ worklists prioritization impacts on reporting times for cervical spine fractures in the emergency department.

              MATERIALS AND METHODS:  Data collection occurred at a major academic health system over two 10-month periods, using integration of AI results (Aidoc, Tel Aviv, Israel) into radiologists' worklist (WL).
              To allow proper software onboarding, a two-month buffer was excluded from the analysis. The analysis focused on one computer-aided detection and triage (CADt) algorithm deployed in the emergency department (ED) setting,
              specifically for cervical spine fracture (c-spine fx) detection. A wait time metric was calculated for cases with suspected positive findings that were AI-notified, and compared to negative cases that were not AI-notified.
              Wait time was defined as the time between the completion of the study acquisition and the time a radiologist opened the case to dictate the report. Median wait times were compared for both positive/negative cases and
              pre/post WL implementation periods.

              RESULTS: The study included 16125 cases, with 7148 cases in the pre-WL period and 8977 cases in the post-WL period. Among these cases, there were 250 positive cases and 6898 negative cases pre-WL, and 226 positive cases
              and 8751 negative cases post-WL. Study population demographic characteristics were consistent across both periods. Median wait time for ED patients was 15.7 minutes for negative cases and 18.7 minutes for positive cases
              Pre-WL integration compared to 16.1 minutes for negative cases and 15.4 minutes for positive cases Post-WL integration. Findings indicate 4.3% prioritization impact after integrating WL, suggesting AI-notified positive
              cases were opened 0.7 minutes earlier than negative cases that were not AI-notified. Before WL integration, this metric was -19% meaning AI-notified positive cases were opened 3 minutes later compared to negative cases
              that were not AI-notified.

              CONCLUSION: Incorporation of AI into radiologists' worklists has demonstrated a 4.3% decreased exam time-to-open compared to negative exams. Thus, AI-triggered notifications for positive cervical spine fractures,
              when integrated into worklists, enhance radiology workflow efficiency and facilitate more timely reporting of acute cases.

          </p>
      </div>

      <!-- Abstract 27 -->
      <div class="abstract">
          <p><strong>Poster Presentation</strong></p>
          <h3>AI-Driven Diagnostic System for Assessing Autism Spectrum Disorder Using Resting-State fMRI</h3>
          <p class="authors"><strong>Authors:</strong> Mohamed Khudri, GTA; Mostafa Abdelrahim, GTA; Ahmed Shalaby, PhD; Mohamed T. Ali, PhD; Yaser A. Elnakib, PhD; Ali Mahmoud, PhD; Asem M. Ali, PhD; Sohail Contractor, MD; Gregory N. Barnes, MD; Ayman El-Baz, PhD</p>
          <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Louisville</p>
          <p class="content">
              <strong>Abstract:</strong> This study presents a diagnostic system using resting-state fMRI and AI methods to assess Autism Spectrum Disorder (ASD). It achieves 97% accuracy, 90% sensitivity, and 99% specificity, effectively identifying ASD severity and related brain regions.
              Abstract: "Early diagnosis of Autism Spectrum Disorder (ASD) remains challenging, hindering the development of non-invasive assessment tools. One major challenge is the reliance on traditional clinical methods,
              such as the Autism Diagnostic Observation Schedule (ADOS) and the Social Responsiveness Scale (SRS), which depend on subjective behavioral assessments and may lead to diagnostic variability.
              To address this, we present a novel diagnostic system that combines resting-state Functional Magnetic Resonance Imaging (fMRI) with Machine Learning (ML) to evaluate ASD in individuals. The primary goal of this
              system is to assess autism severity by accurately identifying specific brain regions that correlate with behavioral patterns observed in autistic individuals.
              The proposed system follows several key steps. First, the fMRI data undergoes preprocessing to correct head motion, reduce susceptibility distortions in the BOLD signal, and align the fMRI with structural MRI (sMRI),
              enhancing resolution. Second, the brain cortex is extracted from the aligned fMRI using the corresponding sMRI. Third, The brain is aligned with the MNI152 standard space and parcellated into 77 regions using the DK atlas.
              Next, fMRI radiomics estimates the correlation matrix to outline the synchronization between each pair of brain regions. The Recursive Feature Elimination (RFE) algorithm is then applied to pinpoint brain areas
              significantly correlated with ASD at a 95% confidence interval. Finally, a Linear Support Vector Machine (LSVM) classifies each subject as either typically developing or autistic, determines ASD severity, and identifies
              abnormal brain regions crucial for detecting dysfunctional neurocircuits involved in autism.
              The system was tested using data from 344 ASD and 374 typically developing individuals from the Autism Brain Imaging Data Exchange II (ABIDE II). Through 5-fold cross-validation, it achieved 97% accuracy, 90% sensitivity,
              and 99% specificity, demonstrating its high reliability for ASD diagnosis and severity classification. This approach offers an innovative, non-invasive method to identify abnormal brain regions and improve ASD understanding,
              potentially aiding in the development of more precise and accessible diagnostic tools.

          </p>
      </div>

      <!-- Abstract 28 -->
      <div class="abstract">
          <p><strong>Poster Presentation</strong></p>
          <h3>A Novel Multi-Scale Fusion Approach Utilizing Vision Transformer and Texture Analysis for Histopathological Diagnosis of Meningioma and Solitary Fibrous Tumors</h3>
          <p class="authors"><strong>Authors:</strong> Mohamed Azam, MSc; Hossam Balaha, MSc; Dibson Gondim, MD; Ayman El-Baz, PhD</p>
          <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Louisville</p>
          <p class="content">
              <strong>Abstract:</strong> Differentiating between meningioma (MEN) and solitary fibrous tumor (SFT) is challenging due to their overlapping morphological features. While both tumors affect the central nervous system (CNS),
              MEN is generally benign, whereas SFT can exhibit aggressive behavior with a high recurrence and metastasis rate. Current diagnostic methods, such as immunohistochemistry (IHC), can be resource-intensive
              and may not always be practical. Accurate diagnosis is crucial for determining appropriate treatment and prognosis. Therefore, artificial intelligence (AI)-based approaches offer a promising solution to
              improve diagnostic accuracy. The objective is to develop a multiscale, rotation-invariant diagnostic method that combines Vision Transformer (ViT) and texture analysis to enhance histopathological diagnosis.

              This method leverages ViT models to capture global features across various magnification levels of whole-slide images (WSIs) while incorporating local texture features to improve classification precision.
              In the first phase, ViT models analyze circular patches at three magnification levels, ensuring rotational and scale invariance to accommodate variations in histopathological imagery. ViT's self-attention
              mechanisms capture intricate details and spatial correlations within the WSIs, providing a comprehensive understanding of histological structures. Concurrently, in the second phase, texture analysis techniques,
              including 3D Circular Local Binary Pattern (3D-CLBP), 3D Gray-Level Co-occurrence Matrix (3D-GLCM), and 3D Gray-Level Run Length Matrix (3D-GLRLM), extract intrinsic patterns such as homogeneity, morphology,
              and connectivity, while considering the three RGB channels to account for color features. The outputs from both stages are fused and passed through a deep neural network for more reliable diagnostic decision-making.
              The proposed method achieved an accuracy of 93.42%, sensitivity of 92.15%, specificity of 94.73%, precision of 94.74%, balanced accuracy of 93.44%, and an F1 score of 93.42%, demonstrating the potential of this approach
              in enhancing histopathological diagnostics.

          </p>
      </div>

      <!-- Abstract 29 -->
      <div class="abstract">
          <p><strong>Poster Presentation</strong></p>
          <h3>FusionAMD: A Novel Multi-Scale Feature Integration Approach for Age-Related Macular Degeneration Detection Using 3D OCT Images</h3>
          <p class="authors"><strong>Authors:</strong> Mohamed Elsharkawy, MSc; Ibrahim Saleh, MD; Rayan Haq; Mohamed Z Haq, MD; Rami Alraefai; Wei Wang, MD; Ayman El-Baz, PhD</p>
          <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Louisville, Louisville, KY, USA</p>
          <p class="content">
              <strong>Abstract:</strong> Age-Related Macular Degeneration (AMD) is a prevalent cause of vision impairment, particularly in older adults, and remains a significant public health concern worldwide.
              Accurate diagnosis is crucial to prevent irreversible damage, but this task remains challenging due to the subtle and complex structural changes in retinal layers,
              which are often difficult to identify using traditional imaging techniques. Three-dimensional Optical Coherence Tomography (3D OCT) scans provide valuable insights into retinal morphology; however,
              effectively utilizing both spatial and volumetric features for reliable AMD classification presents a substantial challenge. To address these limitations, this paper introduces FusionAMD,
              a novel framework that unifies 2D and 3D feature representations for more accurate AMD diagnosis. The proposed architecture consists of three key components: the Adaptive Feature Integration (AFI) block,
              a CNN-based encoder, and a classification head. The AFI block employs lightweight 1 x 1 convolutions combined with softmax activation to emphasize diagnostically significant spatial features that are often
              indicative of AMD progression. Meanwhile, the CNN-based encoder extracts high-level semantic information, capturing the intricate anatomical characteristics of the retinal layers. The features derived from
              the AFI block and the CNN encoder are subsequently aggregated and passed into a classification head, which learns to differentiate between AMD and healthy cases with high precision. The proposed FusionAMD
              framework was rigorously evaluated on a dataset of 300 volumetric OCT scans, demonstrating superior performance compared to existing methods. It achieved an overall classification accuracy of 98.23%,
              highlighting its effectiveness in capturing critical diagnostic patterns within OCT images.
          </p>
      </div>

      <!-- Abstract 30 -->
      <div class="abstract">
          <p><strong>Poster Presentation</strong></p>
          <h3>Role of AI and Genomics in Early and Accurate Identification of Autism Spectrum Disorders: A Brief Review</h3>
          <p class="authors"><strong>Authors:</strong> Yathreb Mohamed, Pharm.D, MSc, MBA, PhD student; Ibrahim Saleh, MD; Salma Karam, MBBCH, MBA; Aaron Buckley; Mohamed Shehata, PhD; Gregory Barnes, MD, PhD; Sohail Contractor, MD; Ayman El-Baz, PhD</p>
          <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Louisville</p>
          <p class="content">
              <strong>Abstract:</strong> Autism Spectrum Disorder (ASD) is a complex neurodevelopmental condition with a strong genetic component, affecting millions worldwide. Early diagnosis is critical for effective intervention,
              yet the heterogeneity of ASD poses significant challenges. Several studies have been investigated the role of genomic markers and artificial intelligence (AI) in early diagnosis of ASD with no definitive conclusion.
              Therefore, this study aims to explore several research questions to fill the gap and open the door for future researchers. First, what are the optimal genomic markers associated with ASD? Second,
              which AI tools are commonly used and can provide effective diagnosis for ASD? Last, does the combination of genomics and AI offers an added diagnostic value? Hence, we conducted a systematic review to
              find all the related studies published in the last decade. After searching well known databases including, scholar Google, PubMed, Scopus, IEEE explore, and Research Gate, using Keywords such as "genomics,"
              "AI," “Autism”, and "machine learning" to identify relevant studies, 46 studies focusing on genomics alone or in combination withAI in ASD diagnosis were identified. A PRISMA chart was employed to ensure transparency,
              and inclusion/exclusion criteria were applied to obtain these studies. The analysis showed that several genomic markers, including NBEA, HOXB3,  HERC1,  NR2F2, and MID2, are strongly associated with ASD.
              These markers are linked to chromatin remodeling, neuronal signaling, and synaptic function, highlighting their potential as diagnostic biomarkers. In terms of AI tools, methods like convolutional neural networks (CNNs),
              gradient boosted trees, and random forests demonstrated high diagnostic accuracy, with some models achieving AUC-ROC values up to 0.955 and accuracy rates exceeding 88%. Studies utilizing AI in combination with
              genomics consistently outperformed those relying only on genomics without using AI. The integration of both approaches offers a more robust and accurate diagnostic tool, paving the way for personalized and early
              intervention strategies. Future research should explore radio genomics as a non-invasive diagnostic direction, leveraging imaging and genomic data to further refine ASD diagnosis and understanding.
          </p>
      </div>

      <!-- Abstract 31 -->
      <div class="abstract">
          <p><strong>Poster Presentation</strong></p>
          <h3>An AI-Based Framework for Renal Rejection Classification Utilizing Genomic and Clinical Markers</h3>
          <p class="authors"><strong>Authors:</strong> Israa Sharaby, MSc; Ibrahim Abdelhalim, MSc; Aya A. Elkhodiry, MSc; Ahmed Alksas, MSc; Ali Mahmoud, PhD; Mohamed Abou El-Ghar, MD; Mohammed Ghazal, PhD; Sameh Saad Ali, MD; Ayman El-Baz, PhD</p>
          <p class="affiliation"><strong>Affiliation/Grants:</strong> University of Louisville</p>
          <p class="content">
              <strong>Abstract:</strong> Renal rejection diagnosis is critical for ensuring appropriate treatment for each rejection subtype. Although biopsy remains the gold standard for diagnosing renal rejection, 
              it is an invasive procedure that poses risks to patients. Thus, there is a need for a non-invasive diagnostic approach that offers comparable or improved accuracy while maintaining patient safety. 
              This study aims to develop a non-invasive, AI-based model to differentiate between antibody-mediated rejection (ABMR) and T-cell mediated rejection (TCMR). Our approach consists of three steps: 
              (i) applying sparse random projection to reduce the dimensionality of the genomic data from 52 to 16 key features, (ii) normalizing and integrating both clinical and genomic data to create a unified feature 
              vector for each patient, and (iii) inputting the feature vector into a transformer-based classifier to distinguish between ABMR and TCMR. The proposed method achieved an accuracy of 94%, 
              demonstrating its ability to accurately classify both rejection types through the integration of clinical and genomic markers. The proposed framework provides a safer, non-invasive alternative approach to biopsy-based 
              diagnosis, to enhance the management of renal transplant patients by reducing the risks associated with invasive diagnostic procedures while maintaining high diagnostic accuracy.
          </p>
      </div>

      <!-- Abstract 32-->
      <div class="abstract">
          <p><strong>Oral Presentation</strong></p>
          <h3>Accurate Prediction of Neoadjuvant Chemotherapy Treatment Response in Breast Cancer Patients: An Explainable AI-Based Approach</h3>
          <p class="authors"><strong>Authors:</strong> Hanaa ZainEldin, PhD; Fatma M. Talaat, PhD; Mohamed Shehata, PhD; Eman Alnaghy, MD; Reham Alghandour, MD; Khadiga M. Ali, PhD; Sohail Contractor, MD; Ayman El-Baz, PhD</p>
          <p class="affiliation"><strong>Affiliation/Grants:</strong> Bioengineering Department, Speed School of Engineering, University of Louisville</p>
          <p class="content">
              <strong>Abstract:</strong> We propose a novel AI-based system for assessing breast cancer (BCa) that aims to predict responses to neoadjuvant chemotherapy (NAC). This system integrates machine learning (ML) and deep learning (DL) methodologies
              to leverage global and local markers, thereby enhancing the accuracy of predictions. The ML component utilizes a decision tree model to identify patterns from global markers derived from pathology assessments,
              which facilitate the determination of molecular subtypes. This analysis incorporates four standard tests: estrogen receptor (ER), progesterone receptor (PR), HER2, and Ki-67. Furthermore,
              it integrates global radiomics descriptors, including tumor morphology, lesion count, and radiological evaluations of axillary nodes categorized as benign or suspicious. In addition to the assessment of global markers,
              the system employs a pre-trained Vision Transformer (ViT-b16) equipped with a multihead adaptive self-attention mechanism to extract local markers from the Region of Interest (ROI) surrounding the breast tumor.
              This approach eliminates the necessity for segmentation, which can adversely affect the accuracy of the local AI model's predictions. The outputs generated by both the ML and DL models are amalgamated using a
              gradient-boosting algorithm to predict responses to NAC at three distinct levels: Partial Response (PR), Complete Response (CR), and Stationary Disease (SD). The proposed system was rigorously tested on 736 2D
              images alongside their corresponding radiomics and pathological markers, with 156 images representing Complete Response (CR), 353 representing Partial Response (PR), and 227 representing Stationary Disease (SD).
              The developed AI-based system achieved an accuracy rate of ~99%. Additionally, explainability was facilitated through the use of heatmaps, which visually delineate areas of high attention in the decision-making process.
              These findings demonstrate significant potential for AI-based early assessments in managing breast cancer.
          </p>
      </div>

    </section>
  </div>

  <footer>
      <p>&copy; 2025 FOMO: Future of Medicine Organization. All Rights Reserved.</p>
  </footer>
</body>
</html>
